digraph {
	graph [size="304.34999999999997,304.34999999999997"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139816738535472 [label="
 (2, 2, 32000)" fillcolor=darkolivegreen1]
	139816738389056 [label=ViewBackward0]
	139816738388480 -> 139816738389056
	139816738388480 [label=CloneBackward0]
	139816738388672 -> 139816738388480
	139816738388672 [label=SliceBackward0]
	139816738388624 -> 139816738388672
	139816738388624 [label=SliceBackward0]
	139816738388336 -> 139816738388624
	139816738388336 [label=SliceBackward0]
	139816738388240 -> 139816738388336
	139816738388240 [label=ConvolutionBackward0]
	139816738386080 -> 139816738388240
	139816738386080 [label=ViewBackward0]
	139816738386368 -> 139816738386080
	139816738386368 [label=MulBackward0]
	139816738386464 -> 139816738386368
	139816738386464 [label=UnsqueezeBackward0]
	139816738386896 -> 139816738386464
	139816738386896 [label=ConvolutionBackward0]
	139816738386944 -> 139816738386896
	139816742825760 [label="encoder.weight
 (512, 1, 32)" fillcolor=lightblue]
	139816742825760 -> 139816738386944
	139816738386944 [label=AccumulateGrad]
	139816738386224 -> 139816738386368
	139816738386224 [label=ViewBackward0]
	139816738389152 -> 139816738386224
	139816738389152 [label=SigmoidBackward0]
	139816738387088 -> 139816738389152
	139816738387088 [label=ConvolutionBackward0]
	139816738389248 -> 139816738387088
	139816738389248 [label=PreluKernelBackward0]
	139816738389440 -> 139816738389248
	139816738389440 [label=AddBackward0]
	139816738389584 -> 139816738389440
	139816738389584 [label=AddBackward0]
	139816738389728 -> 139816738389584
	139816738389728 [label=AddBackward0]
	139816738389872 -> 139816738389728
	139816738389872 [label=AddBackward0]
	139816738389968 -> 139816738389872
	139816738389968 [label=AddBackward0]
	139816738603216 -> 139816738389968
	139816738603216 [label=AddBackward0]
	139816738603360 -> 139816738603216
	139816738603360 [label=AddBackward0]
	139816738603504 -> 139816738603360
	139816738603504 [label=AddBackward0]
	139816738603648 -> 139816738603504
	139816738603648 [label=AddBackward0]
	139816738603792 -> 139816738603648
	139816738603792 [label=AddBackward0]
	139816738603936 -> 139816738603792
	139816738603936 [label=AddBackward0]
	139816738604080 -> 139816738603936
	139816738604080 [label=AddBackward0]
	139816738604224 -> 139816738604080
	139816738604224 [label=AddBackward0]
	139816738604368 -> 139816738604224
	139816738604368 [label=AddBackward0]
	139816738604512 -> 139816738604368
	139816738604512 [label=AddBackward0]
	139816738604656 -> 139816738604512
	139816738604656 [label=AddBackward0]
	139816738604800 -> 139816738604656
	139816738604800 [label=AddBackward0]
	139816738604944 -> 139816738604800
	139816738604944 [label=AddBackward0]
	139816738605088 -> 139816738604944
	139816738605088 [label=AddBackward0]
	139816738605232 -> 139816738605088
	139816738605232 [label=AddBackward0]
	139816738605376 -> 139816738605232
	139816738605376 [label=AddBackward0]
	139816738605520 -> 139816738605376
	139816738605520 [label=AddBackward0]
	139816738605664 -> 139816738605520
	139816738605664 [label=AddBackward0]
	139816738605808 -> 139816738605664
	139816738605808 [label=AddBackward0]
	139816738605952 -> 139816738605808
	139816738605952 [label=ConvolutionBackward0]
	139816738606048 -> 139816738605952
	139816738606048 [label=NativeGroupNormBackward0]
	139816738606240 -> 139816738606048
	139816738606240 [label=PreluKernelBackward0]
	139816738606432 -> 139816738606240
	139816738606432 [label=ConvolutionBackward0]
	139816738606576 -> 139816738606432
	139816738606576 [label=NativeGroupNormBackward0]
	139816738606768 -> 139816738606576
	139816738606768 [label=PreluKernelBackward0]
	139816738606960 -> 139816738606768
	139816738606960 [label=ConvolutionBackward0]
	139816738607104 -> 139816738606960
	139816738607104 [label=ConvolutionBackward0]
	139816738607296 -> 139816738607104
	139816738607296 [label=NativeGroupNormBackward0]
	139816738386896 -> 139816738607296
	139816738607488 -> 139816738607296
	139820613190096 [label="TCN.LN.weight
 (512)" fillcolor=lightblue]
	139820613190096 -> 139816738607488
	139816738607488 [label=AccumulateGrad]
	139816738607440 -> 139816738607296
	139820613190016 [label="TCN.LN.bias
 (512)" fillcolor=lightblue]
	139820613190016 -> 139816738607440
	139816738607440 [label=AccumulateGrad]
	139816738607248 -> 139816738607104
	139820613189696 [label="TCN.BN.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613189696 -> 139816738607248
	139816738607248 [label=AccumulateGrad]
	139816738607200 -> 139816738607104
	139820613196096 [label="TCN.BN.bias
 (128)" fillcolor=lightblue]
	139820613196096 -> 139816738607200
	139816738607200 [label=AccumulateGrad]
	139816738607056 -> 139816738606960
	139820613196016 [label="TCN.TCN.0.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613196016 -> 139816738607056
	139816738607056 [label=AccumulateGrad]
	139816738607008 -> 139816738606960
	139820613195936 [label="TCN.TCN.0.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613195936 -> 139816738607008
	139816738607008 [label=AccumulateGrad]
	139816738606912 -> 139816738606768
	139816738606912 [label=ViewBackward0]
	139816738607392 -> 139816738606912
	139820613195536 [label="TCN.TCN.0.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613195536 -> 139816738607392
	139816738607392 [label=AccumulateGrad]
	139816738606720 -> 139816738606576
	139820613195376 [label="TCN.TCN.0.reg1.weight
 (512)" fillcolor=lightblue]
	139820613195376 -> 139816738606720
	139816738606720 [label=AccumulateGrad]
	139816738606672 -> 139816738606576
	139820613195296 [label="TCN.TCN.0.reg1.bias
 (512)" fillcolor=lightblue]
	139820613195296 -> 139816738606672
	139816738606672 [label=AccumulateGrad]
	139816738606528 -> 139816738606432
	139820613195856 [label="TCN.TCN.0.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613195856 -> 139816738606528
	139816738606528 [label=AccumulateGrad]
	139816738606480 -> 139816738606432
	139820613195776 [label="TCN.TCN.0.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613195776 -> 139816738606480
	139816738606480 [label=AccumulateGrad]
	139816738606384 -> 139816738606240
	139816738606384 [label=ViewBackward0]
	139816738606864 -> 139816738606384
	139820613195456 [label="TCN.TCN.0.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613195456 -> 139816738606864
	139816738606864 [label=AccumulateGrad]
	139816738606192 -> 139816738606048
	139820613195216 [label="TCN.TCN.0.reg2.weight
 (512)" fillcolor=lightblue]
	139820613195216 -> 139816738606192
	139816738606192 [label=AccumulateGrad]
	139816738606144 -> 139816738606048
	139820613195136 [label="TCN.TCN.0.reg2.bias
 (512)" fillcolor=lightblue]
	139820613195136 -> 139816738606144
	139816738606144 [label=AccumulateGrad]
	139816738606000 -> 139816738605952
	139820613195056 [label="TCN.TCN.0.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613195056 -> 139816738606000
	139816738606000 [label=AccumulateGrad]
	139816738605856 -> 139816738605952
	139820613194976 [label="TCN.TCN.0.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613194976 -> 139816738605856
	139816738605856 [label=AccumulateGrad]
	139816738605760 -> 139816738605664
	139816738605760 [label=ConvolutionBackward0]
	139816738606288 -> 139816738605760
	139816738606288 [label=NativeGroupNormBackward0]
	139816738607344 -> 139816738606288
	139816738607344 [label=PreluKernelBackward0]
	139816738607728 -> 139816738607344
	139816738607728 [label=ConvolutionBackward0]
	139816738607872 -> 139816738607728
	139816738607872 [label=NativeGroupNormBackward0]
	139816738608064 -> 139816738607872
	139816738608064 [label=PreluKernelBackward0]
	139816738608256 -> 139816738608064
	139816738608256 [label=ConvolutionBackward0]
	139816738608400 -> 139816738608256
	139816738608400 [label=AddBackward0]
	139816738607104 -> 139816738608400
	139816738608592 -> 139816738608400
	139816738608592 [label=ConvolutionBackward0]
	139816738606048 -> 139816738608592
	139816738608688 -> 139816738608592
	139820613195696 [label="TCN.TCN.0.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613195696 -> 139816738608688
	139816738608688 [label=AccumulateGrad]
	139816738608640 -> 139816738608592
	139820613195616 [label="TCN.TCN.0.res_out.bias
 (128)" fillcolor=lightblue]
	139820613195616 -> 139816738608640
	139816738608640 [label=AccumulateGrad]
	139816738608352 -> 139816738608256
	139820613194896 [label="TCN.TCN.1.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613194896 -> 139816738608352
	139816738608352 [label=AccumulateGrad]
	139816738608304 -> 139816738608256
	139820613194816 [label="TCN.TCN.1.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613194816 -> 139816738608304
	139816738608304 [label=AccumulateGrad]
	139816738608208 -> 139816738608064
	139816738608208 [label=ViewBackward0]
	139816738608496 -> 139816738608208
	139820613194416 [label="TCN.TCN.1.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613194416 -> 139816738608496
	139816738608496 [label=AccumulateGrad]
	139816738608016 -> 139816738607872
	139820613194256 [label="TCN.TCN.1.reg1.weight
 (512)" fillcolor=lightblue]
	139820613194256 -> 139816738608016
	139816738608016 [label=AccumulateGrad]
	139816738607968 -> 139816738607872
	139820613194176 [label="TCN.TCN.1.reg1.bias
 (512)" fillcolor=lightblue]
	139820613194176 -> 139816738607968
	139816738607968 [label=AccumulateGrad]
	139816738607824 -> 139816738607728
	139820613194576 [label="TCN.TCN.1.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613194576 -> 139816738607824
	139816738607824 [label=AccumulateGrad]
	139816738607776 -> 139816738607728
	139820613194496 [label="TCN.TCN.1.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613194496 -> 139816738607776
	139816738607776 [label=AccumulateGrad]
	139816738607152 -> 139816738607344
	139816738607152 [label=ViewBackward0]
	139816738608160 -> 139816738607152
	139820613194336 [label="TCN.TCN.1.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613194336 -> 139816738608160
	139816738608160 [label=AccumulateGrad]
	139816738607680 -> 139816738606288
	139820613194096 [label="TCN.TCN.1.reg2.weight
 (512)" fillcolor=lightblue]
	139820613194096 -> 139816738607680
	139816738607680 [label=AccumulateGrad]
	139816738606816 -> 139816738606288
	139820613194016 [label="TCN.TCN.1.reg2.bias
 (512)" fillcolor=lightblue]
	139820613194016 -> 139816738606816
	139816738606816 [label=AccumulateGrad]
	139816738606096 -> 139816738605760
	139820613193776 [label="TCN.TCN.1.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613193776 -> 139816738606096
	139816738606096 [label=AccumulateGrad]
	139816738605904 -> 139816738605760
	139820613193696 [label="TCN.TCN.1.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613193696 -> 139816738605904
	139816738605904 [label=AccumulateGrad]
	139816738605616 -> 139816738605520
	139816738605616 [label=ConvolutionBackward0]
	139816738606624 -> 139816738605616
	139816738606624 [label=NativeGroupNormBackward0]
	139816738608544 -> 139816738606624
	139816738608544 [label=PreluKernelBackward0]
	139816738608832 -> 139816738608544
	139816738608832 [label=ConvolutionBackward0]
	139816738608976 -> 139816738608832
	139816738608976 [label=NativeGroupNormBackward0]
	139816738609168 -> 139816738608976
	139816738609168 [label=PreluKernelBackward0]
	139816738609360 -> 139816738609168
	139816738609360 [label=ConvolutionBackward0]
	139816738609504 -> 139816738609360
	139816738609504 [label=AddBackward0]
	139816738608400 -> 139816738609504
	139816738609696 -> 139816738609504
	139816738609696 [label=ConvolutionBackward0]
	139816738606288 -> 139816738609696
	139816738609792 -> 139816738609696
	139820613194736 [label="TCN.TCN.1.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613194736 -> 139816738609792
	139816738609792 [label=AccumulateGrad]
	139816738609744 -> 139816738609696
	139820613194656 [label="TCN.TCN.1.res_out.bias
 (128)" fillcolor=lightblue]
	139820613194656 -> 139816738609744
	139816738609744 [label=AccumulateGrad]
	139816738609456 -> 139816738609360
	139820613193616 [label="TCN.TCN.2.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613193616 -> 139816738609456
	139816738609456 [label=AccumulateGrad]
	139816738609408 -> 139816738609360
	139820613193536 [label="TCN.TCN.2.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613193536 -> 139816738609408
	139816738609408 [label=AccumulateGrad]
	139816738609312 -> 139816738609168
	139816738609312 [label=ViewBackward0]
	139816738609600 -> 139816738609312
	139820613193136 [label="TCN.TCN.2.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613193136 -> 139816738609600
	139816738609600 [label=AccumulateGrad]
	139816738609120 -> 139816738608976
	139820613192976 [label="TCN.TCN.2.reg1.weight
 (512)" fillcolor=lightblue]
	139820613192976 -> 139816738609120
	139816738609120 [label=AccumulateGrad]
	139816738609072 -> 139816738608976
	139820613192896 [label="TCN.TCN.2.reg1.bias
 (512)" fillcolor=lightblue]
	139820613192896 -> 139816738609072
	139816738609072 [label=AccumulateGrad]
	139816738608928 -> 139816738608832
	139820613193456 [label="TCN.TCN.2.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613193456 -> 139816738608928
	139816738608928 [label=AccumulateGrad]
	139816738608880 -> 139816738608832
	139820613193376 [label="TCN.TCN.2.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613193376 -> 139816738608880
	139816738608880 [label=AccumulateGrad]
	139816738608448 -> 139816738608544
	139816738608448 [label=ViewBackward0]
	139816738609264 -> 139816738608448
	139820613193056 [label="TCN.TCN.2.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613193056 -> 139816738609264
	139816738609264 [label=AccumulateGrad]
	139816738608784 -> 139816738606624
	139820613193936 [label="TCN.TCN.2.reg2.weight
 (512)" fillcolor=lightblue]
	139820613193936 -> 139816738608784
	139816738608784 [label=AccumulateGrad]
	139816738608112 -> 139816738606624
	139820613193856 [label="TCN.TCN.2.reg2.bias
 (512)" fillcolor=lightblue]
	139820613193856 -> 139816738608112
	139816738608112 [label=AccumulateGrad]
	139816738606336 -> 139816738605616
	139820613198336 [label="TCN.TCN.2.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613198336 -> 139816738606336
	139816738606336 [label=AccumulateGrad]
	139816738605712 -> 139816738605616
	139820613198256 [label="TCN.TCN.2.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613198256 -> 139816738605712
	139816738605712 [label=AccumulateGrad]
	139816738605472 -> 139816738605376
	139816738605472 [label=ConvolutionBackward0]
	139816738607920 -> 139816738605472
	139816738607920 [label=NativeGroupNormBackward0]
	139816738609648 -> 139816738607920
	139816738609648 [label=PreluKernelBackward0]
	139816738609936 -> 139816738609648
	139816738609936 [label=ConvolutionBackward0]
	139816738610080 -> 139816738609936
	139816738610080 [label=NativeGroupNormBackward0]
	139816738610272 -> 139816738610080
	139816738610272 [label=PreluKernelBackward0]
	139816738610464 -> 139816738610272
	139816738610464 [label=ConvolutionBackward0]
	139816738610608 -> 139816738610464
	139816738610608 [label=AddBackward0]
	139816738609504 -> 139816738610608
	139816738610800 -> 139816738610608
	139816738610800 [label=ConvolutionBackward0]
	139816738606624 -> 139816738610800
	139816738610896 -> 139816738610800
	139820613193296 [label="TCN.TCN.2.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613193296 -> 139816738610896
	139816738610896 [label=AccumulateGrad]
	139816738610848 -> 139816738610800
	139820613193216 [label="TCN.TCN.2.res_out.bias
 (128)" fillcolor=lightblue]
	139820613193216 -> 139816738610848
	139816738610848 [label=AccumulateGrad]
	139816738610560 -> 139816738610464
	139820613191376 [label="TCN.TCN.3.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613191376 -> 139816738610560
	139816738610560 [label=AccumulateGrad]
	139816738610512 -> 139816738610464
	139820613191296 [label="TCN.TCN.3.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613191296 -> 139816738610512
	139816738610512 [label=AccumulateGrad]
	139816738610416 -> 139816738610272
	139816738610416 [label=ViewBackward0]
	139816738610704 -> 139816738610416
	139820613151664 [label="TCN.TCN.3.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613151664 -> 139816738610704
	139816738610704 [label=AccumulateGrad]
	139816738610224 -> 139816738610080
	139820613143664 [label="TCN.TCN.3.reg1.weight
 (512)" fillcolor=lightblue]
	139820613143664 -> 139816738610224
	139816738610224 [label=AccumulateGrad]
	139816738610176 -> 139816738610080
	139820613143584 [label="TCN.TCN.3.reg1.bias
 (512)" fillcolor=lightblue]
	139820613143584 -> 139816738610176
	139816738610176 [label=AccumulateGrad]
	139816738610032 -> 139816738609936
	139820613151744 [label="TCN.TCN.3.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613151744 -> 139816738610032
	139816738610032 [label=AccumulateGrad]
	139816738609984 -> 139816738609936
	139820613151904 [label="TCN.TCN.3.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613151904 -> 139816738609984
	139816738609984 [label=AccumulateGrad]
	139816738609552 -> 139816738609648
	139816738609552 [label=ViewBackward0]
	139816738610368 -> 139816738609552
	139820613151584 [label="TCN.TCN.3.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613151584 -> 139816738610368
	139816738610368 [label=AccumulateGrad]
	139816738609888 -> 139816738607920
	139820613143264 [label="TCN.TCN.3.reg2.weight
 (512)" fillcolor=lightblue]
	139820613143264 -> 139816738609888
	139816738609888 [label=AccumulateGrad]
	139816738609216 -> 139816738607920
	139820613151504 [label="TCN.TCN.3.reg2.bias
 (512)" fillcolor=lightblue]
	139820613151504 -> 139816738609216
	139816738609216 [label=AccumulateGrad]
	139816738607632 -> 139816738605472
	139820613151424 [label="TCN.TCN.3.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613151424 -> 139816738607632
	139816738607632 [label=AccumulateGrad]
	139816738605568 -> 139816738605472
	139820613143424 [label="TCN.TCN.3.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613143424 -> 139816738605568
	139816738605568 [label=AccumulateGrad]
	139816738605328 -> 139816738605232
	139816738605328 [label=ConvolutionBackward0]
	139816738609024 -> 139816738605328
	139816738609024 [label=NativeGroupNormBackward0]
	139816738610752 -> 139816738609024
	139816738610752 [label=PreluKernelBackward0]
	139816738611040 -> 139816738610752
	139816738611040 [label=ConvolutionBackward0]
	139816738611184 -> 139816738611040
	139816738611184 [label=NativeGroupNormBackward0]
	139816738611376 -> 139816738611184
	139816738611376 [label=PreluKernelBackward0]
	139816738611568 -> 139816738611376
	139816738611568 [label=ConvolutionBackward0]
	139816738611712 -> 139816738611568
	139816738611712 [label=AddBackward0]
	139816738610608 -> 139816738611712
	139816738611904 -> 139816738611712
	139816738611904 [label=ConvolutionBackward0]
	139816738607920 -> 139816738611904
	139816738612000 -> 139816738611904
	139820613151824 [label="TCN.TCN.3.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613151824 -> 139816738612000
	139816738612000 [label=AccumulateGrad]
	139816738611952 -> 139816738611904
	139820613143504 [label="TCN.TCN.3.res_out.bias
 (128)" fillcolor=lightblue]
	139820613143504 -> 139816738611952
	139816738611952 [label=AccumulateGrad]
	139816738611664 -> 139816738611568
	139820613143344 [label="TCN.TCN.4.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613143344 -> 139816738611664
	139816738611664 [label=AccumulateGrad]
	139816738611616 -> 139816738611568
	139820613151344 [label="TCN.TCN.4.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613151344 -> 139816738611616
	139816738611616 [label=AccumulateGrad]
	139816738611520 -> 139816738611376
	139816738611520 [label=ViewBackward0]
	139816738611808 -> 139816738611520
	139820613151184 [label="TCN.TCN.4.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613151184 -> 139816738611808
	139816738611808 [label=AccumulateGrad]
	139816738611328 -> 139816738611184
	139820613143024 [label="TCN.TCN.4.reg1.weight
 (512)" fillcolor=lightblue]
	139820613143024 -> 139816738611328
	139816738611328 [label=AccumulateGrad]
	139816738611280 -> 139816738611184
	139820613142944 [label="TCN.TCN.4.reg1.bias
 (512)" fillcolor=lightblue]
	139820613142944 -> 139816738611280
	139816738611280 [label=AccumulateGrad]
	139816738611136 -> 139816738611040
	139820613151264 [label="TCN.TCN.4.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613151264 -> 139816738611136
	139816738611136 [label=AccumulateGrad]
	139816738611088 -> 139816738611040
	139820613143184 [label="TCN.TCN.4.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613143184 -> 139816738611088
	139816738611088 [label=AccumulateGrad]
	139816738610656 -> 139816738610752
	139816738610656 [label=ViewBackward0]
	139816738611472 -> 139816738610656
	139820613151104 [label="TCN.TCN.4.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613151104 -> 139816738611472
	139816738611472 [label=AccumulateGrad]
	139816738610992 -> 139816738609024
	139820613142624 [label="TCN.TCN.4.reg2.weight
 (512)" fillcolor=lightblue]
	139820613142624 -> 139816738610992
	139816738610992 [label=AccumulateGrad]
	139816738610320 -> 139816738609024
	139820613151024 [label="TCN.TCN.4.reg2.bias
 (512)" fillcolor=lightblue]
	139820613151024 -> 139816738610320
	139816738610320 [label=AccumulateGrad]
	139816738608736 -> 139816738605328
	139820613150944 [label="TCN.TCN.4.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613150944 -> 139816738608736
	139816738608736 [label=AccumulateGrad]
	139816738605424 -> 139816738605328
	139820613142784 [label="TCN.TCN.4.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613142784 -> 139816738605424
	139816738605424 [label=AccumulateGrad]
	139816738605184 -> 139816738605088
	139816738605184 [label=ConvolutionBackward0]
	139816738610128 -> 139816738605184
	139816738610128 [label=NativeGroupNormBackward0]
	139816738611856 -> 139816738610128
	139816738611856 [label=PreluKernelBackward0]
	139816738612192 -> 139816738611856
	139816738612192 [label=ConvolutionBackward0]
	139816738612336 -> 139816738612192
	139816738612336 [label=NativeGroupNormBackward0]
	139816738612528 -> 139816738612336
	139816738612528 [label=PreluKernelBackward0]
	139816738612720 -> 139816738612528
	139816738612720 [label=ConvolutionBackward0]
	139816738612864 -> 139816738612720
	139816738612864 [label=AddBackward0]
	139816738611712 -> 139816738612864
	139816738613056 -> 139816738612864
	139816738613056 [label=ConvolutionBackward0]
	139816738609024 -> 139816738613056
	139816738613152 -> 139816738613056
	139820613143104 [label="TCN.TCN.4.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613143104 -> 139816738613152
	139816738613152 [label=AccumulateGrad]
	139816738613104 -> 139816738613056
	139820613142864 [label="TCN.TCN.4.res_out.bias
 (128)" fillcolor=lightblue]
	139820613142864 -> 139816738613104
	139816738613104 [label=AccumulateGrad]
	139816738612816 -> 139816738612720
	139820613142704 [label="TCN.TCN.5.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613142704 -> 139816738612816
	139816738612816 [label=AccumulateGrad]
	139816738612768 -> 139816738612720
	139820613142384 [label="TCN.TCN.5.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613142384 -> 139816738612768
	139816738612768 [label=AccumulateGrad]
	139816738612672 -> 139816738612528
	139816738612672 [label=ViewBackward0]
	139816738612960 -> 139816738612672
	139820613150624 [label="TCN.TCN.5.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613150624 -> 139816738612960
	139816738612960 [label=AccumulateGrad]
	139816738612480 -> 139816738612336
	139820613142064 [label="TCN.TCN.5.reg1.weight
 (512)" fillcolor=lightblue]
	139820613142064 -> 139816738612480
	139816738612480 [label=AccumulateGrad]
	139816738612432 -> 139816738612336
	139820613141984 [label="TCN.TCN.5.reg1.bias
 (512)" fillcolor=lightblue]
	139820613141984 -> 139816738612432
	139816738612432 [label=AccumulateGrad]
	139816738612288 -> 139816738612192
	139820613150864 [label="TCN.TCN.5.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613150864 -> 139816738612288
	139816738612288 [label=AccumulateGrad]
	139816738612240 -> 139816738612192
	139820613142544 [label="TCN.TCN.5.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613142544 -> 139816738612240
	139816738612240 [label=AccumulateGrad]
	139816738611760 -> 139816738611856
	139816738611760 [label=ViewBackward0]
	139816738612624 -> 139816738611760
	139820613150544 [label="TCN.TCN.5.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613150544 -> 139816738612624
	139816738612624 [label=AccumulateGrad]
	139816738612144 -> 139816738610128
	139820613142144 [label="TCN.TCN.5.reg2.weight
 (512)" fillcolor=lightblue]
	139820613142144 -> 139816738612144
	139816738612144 [label=AccumulateGrad]
	139816738611424 -> 139816738610128
	139820613150784 [label="TCN.TCN.5.reg2.bias
 (512)" fillcolor=lightblue]
	139820613150784 -> 139816738611424
	139816738611424 [label=AccumulateGrad]
	139816738609840 -> 139816738605184
	139820613150704 [label="TCN.TCN.5.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613150704 -> 139816738609840
	139816738609840 [label=AccumulateGrad]
	139816738605280 -> 139816738605184
	139820613142304 [label="TCN.TCN.5.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613142304 -> 139816738605280
	139816738605280 [label=AccumulateGrad]
	139816738605040 -> 139816738604944
	139816738605040 [label=ConvolutionBackward0]
	139816738611232 -> 139816738605040
	139816738611232 [label=NativeGroupNormBackward0]
	139816738613008 -> 139816738611232
	139816738613008 [label=PreluKernelBackward0]
	139816738613296 -> 139816738613008
	139816738613296 [label=ConvolutionBackward0]
	139816738613440 -> 139816738613296
	139816738613440 [label=NativeGroupNormBackward0]
	139816738613632 -> 139816738613440
	139816738613632 [label=PreluKernelBackward0]
	139816738613824 -> 139816738613632
	139816738613824 [label=ConvolutionBackward0]
	139816738613968 -> 139816738613824
	139816738613968 [label=AddBackward0]
	139816738612864 -> 139816738613968
	139816738614160 -> 139816738613968
	139816738614160 [label=ConvolutionBackward0]
	139816738610128 -> 139816738614160
	139816738614256 -> 139816738614160
	139820613142464 [label="TCN.TCN.5.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613142464 -> 139816738614256
	139816738614256 [label=AccumulateGrad]
	139816738614208 -> 139816738614160
	139820613141904 [label="TCN.TCN.5.res_out.bias
 (128)" fillcolor=lightblue]
	139820613141904 -> 139816738614208
	139816738614208 [label=AccumulateGrad]
	139816738613920 -> 139816738613824
	139820613142224 [label="TCN.TCN.6.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613142224 -> 139816738613920
	139816738613920 [label=AccumulateGrad]
	139816738613872 -> 139816738613824
	139820613141664 [label="TCN.TCN.6.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613141664 -> 139816738613872
	139816738613872 [label=AccumulateGrad]
	139816738613776 -> 139816738613632
	139816738613776 [label=ViewBackward0]
	139816738614064 -> 139816738613776
	139820613141424 [label="TCN.TCN.6.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613141424 -> 139816738614064
	139816738614064 [label=AccumulateGrad]
	139816738613584 -> 139816738613440
	139820613150224 [label="TCN.TCN.6.reg1.weight
 (512)" fillcolor=lightblue]
	139820613150224 -> 139816738613584
	139816738613584 [label=AccumulateGrad]
	139816738613536 -> 139816738613440
	139820613156784 [label="TCN.TCN.6.reg1.bias
 (512)" fillcolor=lightblue]
	139820613156784 -> 139816738613536
	139816738613536 [label=AccumulateGrad]
	139816738613392 -> 139816738613296
	139820613150464 [label="TCN.TCN.6.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613150464 -> 139816738613392
	139816738613392 [label=AccumulateGrad]
	139816738613344 -> 139816738613296
	139820613150384 [label="TCN.TCN.6.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613150384 -> 139816738613344
	139816738613344 [label=AccumulateGrad]
	139816738612912 -> 139816738613008
	139816738612912 [label=ViewBackward0]
	139816738613728 -> 139816738612912
	139820613150304 [label="TCN.TCN.6.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613150304 -> 139816738613728
	139816738613728 [label=AccumulateGrad]
	139816738613248 -> 139816738611232
	139820613156704 [label="TCN.TCN.6.reg2.weight
 (512)" fillcolor=lightblue]
	139820613156704 -> 139816738613248
	139816738613248 [label=AccumulateGrad]
	139816738612576 -> 139816738611232
	139820613141584 [label="TCN.TCN.6.reg2.bias
 (512)" fillcolor=lightblue]
	139820613141584 -> 139816738612576
	139816738612576 [label=AccumulateGrad]
	139816738610944 -> 139816738605040
	139820613141504 [label="TCN.TCN.6.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613141504 -> 139816738610944
	139816738610944 [label=AccumulateGrad]
	139816738605136 -> 139816738605040
	139820613141184 [label="TCN.TCN.6.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613141184 -> 139816738605136
	139816738605136 [label=AccumulateGrad]
	139816738604896 -> 139816738604800
	139816738604896 [label=ConvolutionBackward0]
	139816738612384 -> 139816738604896
	139816738612384 [label=NativeGroupNormBackward0]
	139816738614112 -> 139816738612384
	139816738614112 [label=PreluKernelBackward0]
	139816738614400 -> 139816738614112
	139816738614400 [label=ConvolutionBackward0]
	139816738614544 -> 139816738614400
	139816738614544 [label=NativeGroupNormBackward0]
	139816738614736 -> 139816738614544
	139816738614736 [label=PreluKernelBackward0]
	139816738614928 -> 139816738614736
	139816738614928 [label=ConvolutionBackward0]
	139816738615072 -> 139816738614928
	139816738615072 [label=AddBackward0]
	139816738613968 -> 139816738615072
	139816738615264 -> 139816738615072
	139816738615264 [label=ConvolutionBackward0]
	139816738611232 -> 139816738615264
	139816738615360 -> 139816738615264
	139820613141824 [label="TCN.TCN.6.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613141824 -> 139816738615360
	139816738615360 [label=AccumulateGrad]
	139816738615312 -> 139816738615264
	139820613141744 [label="TCN.TCN.6.res_out.bias
 (128)" fillcolor=lightblue]
	139820613141744 -> 139816738615312
	139816738615312 [label=AccumulateGrad]
	139816738615024 -> 139816738614928
	139820613150144 [label="TCN.TCN.7.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613150144 -> 139816738615024
	139816738615024 [label=AccumulateGrad]
	139816738614976 -> 139816738614928
	139820613150064 [label="TCN.TCN.7.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613150064 -> 139816738614976
	139816738614976 [label=AccumulateGrad]
	139816738614880 -> 139816738614736
	139816738614880 [label=ViewBackward0]
	139816738615168 -> 139816738614880
	139820613140944 [label="TCN.TCN.7.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613140944 -> 139816738615168
	139816738615168 [label=AccumulateGrad]
	139816738614688 -> 139816738614544
	139820613149904 [label="TCN.TCN.7.reg1.weight
 (512)" fillcolor=lightblue]
	139820613149904 -> 139816738614688
	139816738614688 [label=AccumulateGrad]
	139816738614640 -> 139816738614544
	139820613156464 [label="TCN.TCN.7.reg1.bias
 (512)" fillcolor=lightblue]
	139820613156464 -> 139816738614640
	139816738614640 [label=AccumulateGrad]
	139816738614496 -> 139816738614400
	139820613156624 [label="TCN.TCN.7.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613156624 -> 139816738614496
	139816738614496 [label=AccumulateGrad]
	139816738614448 -> 139816738614400
	139820613156544 [label="TCN.TCN.7.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613156544 -> 139816738614448
	139816738614448 [label=AccumulateGrad]
	139816738614016 -> 139816738614112
	139816738614016 [label=ViewBackward0]
	139816738614832 -> 139816738614016
	139820613149984 [label="TCN.TCN.7.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613149984 -> 139816738614832
	139816738614832 [label=AccumulateGrad]
	139816738614352 -> 139816738612384
	139820613156384 [label="TCN.TCN.7.reg2.weight
 (512)" fillcolor=lightblue]
	139820613156384 -> 139816738614352
	139816738614352 [label=AccumulateGrad]
	139816738613680 -> 139816738612384
	139820613141104 [label="TCN.TCN.7.reg2.bias
 (512)" fillcolor=lightblue]
	139820613141104 -> 139816738613680
	139816738613680 [label=AccumulateGrad]
	139816738612048 -> 139816738604896
	139820613141024 [label="TCN.TCN.7.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613141024 -> 139816738612048
	139816738612048 [label=AccumulateGrad]
	139816738604992 -> 139816738604896
	139820613140704 [label="TCN.TCN.7.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613140704 -> 139816738604992
	139816738604992 [label=AccumulateGrad]
	139816738604752 -> 139816738604656
	139816738604752 [label=ConvolutionBackward0]
	139816738613488 -> 139816738604752
	139816738613488 [label=NativeGroupNormBackward0]
	139816738615216 -> 139816738613488
	139816738615216 [label=PreluKernelBackward0]
	139816738615504 -> 139816738615216
	139816738615504 [label=ConvolutionBackward0]
	139816738615648 -> 139816738615504
	139816738615648 [label=NativeGroupNormBackward0]
	139816738615840 -> 139816738615648
	139816738615840 [label=PreluKernelBackward0]
	139816738616032 -> 139816738615840
	139816738616032 [label=ConvolutionBackward0]
	139816738616176 -> 139816738616032
	139816738616176 [label=AddBackward0]
	139816738615072 -> 139816738616176
	139816738616368 -> 139816738616176
	139816738616368 [label=ConvolutionBackward0]
	139816738612384 -> 139816738616368
	139816738616464 -> 139816738616368
	139820613141344 [label="TCN.TCN.7.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613141344 -> 139816738616464
	139816738616464 [label=AccumulateGrad]
	139816738616416 -> 139816738616368
	139820613141264 [label="TCN.TCN.7.res_out.bias
 (128)" fillcolor=lightblue]
	139820613141264 -> 139816738616416
	139816738616416 [label=AccumulateGrad]
	139816738616128 -> 139816738616032
	139820613149824 [label="TCN.TCN.8.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613149824 -> 139816738616128
	139816738616128 [label=AccumulateGrad]
	139816738616080 -> 139816738616032
	139820613149744 [label="TCN.TCN.8.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613149744 -> 139816738616080
	139816738616080 [label=AccumulateGrad]
	139816738615984 -> 139816738615840
	139816738615984 [label=ViewBackward0]
	139816738616272 -> 139816738615984
	139820613149664 [label="TCN.TCN.8.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613149664 -> 139816738616272
	139816738616272 [label=AccumulateGrad]
	139816738615792 -> 139816738615648
	139820613156144 [label="TCN.TCN.8.reg1.weight
 (512)" fillcolor=lightblue]
	139820613156144 -> 139816738615792
	139816738615792 [label=AccumulateGrad]
	139816738615744 -> 139816738615648
	139820613156064 [label="TCN.TCN.8.reg1.bias
 (512)" fillcolor=lightblue]
	139820613156064 -> 139816738615744
	139816738615744 [label=AccumulateGrad]
	139816738615600 -> 139816738615504
	139820613156304 [label="TCN.TCN.8.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613156304 -> 139816738615600
	139816738615600 [label=AccumulateGrad]
	139816738615552 -> 139816738615504
	139820613156224 [label="TCN.TCN.8.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613156224 -> 139816738615552
	139816738615552 [label=AccumulateGrad]
	139816738615120 -> 139816738615216
	139816738615120 [label=ViewBackward0]
	139816738615936 -> 139816738615120
	139820613149584 [label="TCN.TCN.8.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613149584 -> 139816738615936
	139816738615936 [label=AccumulateGrad]
	139816738615456 -> 139816738613488
	139820613140624 [label="TCN.TCN.8.reg2.weight
 (512)" fillcolor=lightblue]
	139820613140624 -> 139816738615456
	139816738615456 [label=AccumulateGrad]
	139816738614784 -> 139816738613488
	139820613140544 [label="TCN.TCN.8.reg2.bias
 (512)" fillcolor=lightblue]
	139820613140544 -> 139816738614784
	139816738614784 [label=AccumulateGrad]
	139816738613200 -> 139816738604752
	139820613149504 [label="TCN.TCN.8.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613149504 -> 139816738613200
	139816738613200 [label=AccumulateGrad]
	139816738604848 -> 139816738604752
	139820613149424 [label="TCN.TCN.8.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613149424 -> 139816738604848
	139816738604848 [label=AccumulateGrad]
	139816738604608 -> 139816738604512
	139816738604608 [label=ConvolutionBackward0]
	139816738614592 -> 139816738604608
	139816738614592 [label=NativeGroupNormBackward0]
	139816738616320 -> 139816738614592
	139816738616320 [label=PreluKernelBackward0]
	139816738616608 -> 139816738616320
	139816738616608 [label=ConvolutionBackward0]
	139816738616752 -> 139816738616608
	139816738616752 [label=NativeGroupNormBackward0]
	139816738616944 -> 139816738616752
	139816738616944 [label=PreluKernelBackward0]
	139816738617136 -> 139816738616944
	139816738617136 [label=ConvolutionBackward0]
	139816738617280 -> 139816738617136
	139816738617280 [label=AddBackward0]
	139816738616176 -> 139816738617280
	139816738617472 -> 139816738617280
	139816738617472 [label=ConvolutionBackward0]
	139816738613488 -> 139816738617472
	139816738617568 -> 139816738617472
	139820613140864 [label="TCN.TCN.8.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613140864 -> 139816738617568
	139816738617568 [label=AccumulateGrad]
	139816738617520 -> 139816738617472
	139820613140784 [label="TCN.TCN.8.res_out.bias
 (128)" fillcolor=lightblue]
	139820613140784 -> 139816738617520
	139816738617520 [label=AccumulateGrad]
	139816738617232 -> 139816738617136
	139820613155984 [label="TCN.TCN.9.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613155984 -> 139816738617232
	139816738617232 [label=AccumulateGrad]
	139816738617184 -> 139816738617136
	139820613155904 [label="TCN.TCN.9.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613155904 -> 139816738617184
	139816738617184 [label=AccumulateGrad]
	139816738617088 -> 139816738616944
	139816738617088 [label=ViewBackward0]
	139816738617376 -> 139816738617088
	139820613149184 [label="TCN.TCN.9.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613149184 -> 139816738617376
	139816738617376 [label=AccumulateGrad]
	139816738616896 -> 139816738616752
	139820613155664 [label="TCN.TCN.9.reg1.weight
 (512)" fillcolor=lightblue]
	139820613155664 -> 139816738616896
	139816738616896 [label=AccumulateGrad]
	139816738616848 -> 139816738616752
	139820613155584 [label="TCN.TCN.9.reg1.bias
 (512)" fillcolor=lightblue]
	139820613155584 -> 139816738616848
	139816738616848 [label=AccumulateGrad]
	139816738616704 -> 139816738616608
	139820613149344 [label="TCN.TCN.9.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613149344 -> 139816738616704
	139816738616704 [label=AccumulateGrad]
	139816738616656 -> 139816738616608
	139820613149264 [label="TCN.TCN.9.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613149264 -> 139816738616656
	139816738616656 [label=AccumulateGrad]
	139816738616224 -> 139816738616320
	139816738616224 [label=ViewBackward0]
	139816738617040 -> 139816738616224
	139820613149104 [label="TCN.TCN.9.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613149104 -> 139816738617040
	139816738617040 [label=AccumulateGrad]
	139816738616560 -> 139816738614592
	139820613149024 [label="TCN.TCN.9.reg2.weight
 (512)" fillcolor=lightblue]
	139820613149024 -> 139816738616560
	139816738616560 [label=AccumulateGrad]
	139816738615888 -> 139816738614592
	139820613148944 [label="TCN.TCN.9.reg2.bias
 (512)" fillcolor=lightblue]
	139820613148944 -> 139816738615888
	139816738615888 [label=AccumulateGrad]
	139816738614304 -> 139816738604608
	139820613155504 [label="TCN.TCN.9.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613155504 -> 139816738614304
	139816738614304 [label=AccumulateGrad]
	139816738604704 -> 139816738604608
	139820613155424 [label="TCN.TCN.9.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613155424 -> 139816738604704
	139816738604704 [label=AccumulateGrad]
	139816738604464 -> 139816738604368
	139816738604464 [label=ConvolutionBackward0]
	139816738615696 -> 139816738604464
	139816738615696 [label=NativeGroupNormBackward0]
	139816738617424 -> 139816738615696
	139816738617424 [label=PreluKernelBackward0]
	139816738617712 -> 139816738617424
	139816738617712 [label=ConvolutionBackward0]
	139816738617856 -> 139816738617712
	139816738617856 [label=NativeGroupNormBackward0]
	139816738618048 -> 139816738617856
	139816738618048 [label=PreluKernelBackward0]
	139816738618240 -> 139816738618048
	139816738618240 [label=ConvolutionBackward0]
	139816738618384 -> 139816738618240
	139816738618384 [label=AddBackward0]
	139816738617280 -> 139816738618384
	139816738618576 -> 139816738618384
	139816738618576 [label=ConvolutionBackward0]
	139816738614592 -> 139816738618576
	139816738618672 -> 139816738618576
	139820613155824 [label="TCN.TCN.9.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613155824 -> 139816738618672
	139816738618672 [label=AccumulateGrad]
	139816738618624 -> 139816738618576
	139820613155744 [label="TCN.TCN.9.res_out.bias
 (128)" fillcolor=lightblue]
	139820613155744 -> 139816738618624
	139816738618624 [label=AccumulateGrad]
	139816738618336 -> 139816738618240
	139820613148864 [label="TCN.TCN.10.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613148864 -> 139816738618336
	139816738618336 [label=AccumulateGrad]
	139816738618288 -> 139816738618240
	139820613148784 [label="TCN.TCN.10.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613148784 -> 139816738618288
	139816738618288 [label=AccumulateGrad]
	139816738618192 -> 139816738618048
	139816738618192 [label=ViewBackward0]
	139816738618480 -> 139816738618192
	139820613155184 [label="TCN.TCN.10.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613155184 -> 139816738618480
	139816738618480 [label=AccumulateGrad]
	139816738618000 -> 139816738617856
	139820613148544 [label="TCN.TCN.10.reg1.weight
 (512)" fillcolor=lightblue]
	139820613148544 -> 139816738618000
	139816738618000 [label=AccumulateGrad]
	139816738617952 -> 139816738617856
	139820613148464 [label="TCN.TCN.10.reg1.bias
 (512)" fillcolor=lightblue]
	139820613148464 -> 139816738617952
	139816738617952 [label=AccumulateGrad]
	139816738617808 -> 139816738617712
	139820613155344 [label="TCN.TCN.10.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613155344 -> 139816738617808
	139816738617808 [label=AccumulateGrad]
	139816738617760 -> 139816738617712
	139820613155264 [label="TCN.TCN.10.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613155264 -> 139816738617760
	139816738617760 [label=AccumulateGrad]
	139816738617328 -> 139816738617424
	139816738617328 [label=ViewBackward0]
	139816738618144 -> 139816738617328
	139820613155104 [label="TCN.TCN.10.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613155104 -> 139816738618144
	139816738618144 [label=AccumulateGrad]
	139816738617664 -> 139816738615696
	139820613155024 [label="TCN.TCN.10.reg2.weight
 (512)" fillcolor=lightblue]
	139820613155024 -> 139816738617664
	139816738617664 [label=AccumulateGrad]
	139816738616992 -> 139816738615696
	139820613154944 [label="TCN.TCN.10.reg2.bias
 (512)" fillcolor=lightblue]
	139820613154944 -> 139816738616992
	139816738616992 [label=AccumulateGrad]
	139816738615408 -> 139816738604464
	139820613148224 [label="TCN.TCN.10.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613148224 -> 139816738615408
	139816738615408 [label=AccumulateGrad]
	139816738604560 -> 139816738604464
	139820613148144 [label="TCN.TCN.10.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613148144 -> 139816738604560
	139816738604560 [label=AccumulateGrad]
	139816738604320 -> 139816738604224
	139816738604320 [label=ConvolutionBackward0]
	139816738616800 -> 139816738604320
	139816738616800 [label=NativeGroupNormBackward0]
	139816738618528 -> 139816738616800
	139816738618528 [label=PreluKernelBackward0]
	139816738618816 -> 139816738618528
	139816738618816 [label=ConvolutionBackward0]
	139816738618960 -> 139816738618816
	139816738618960 [label=NativeGroupNormBackward0]
	139816738619152 -> 139816738618960
	139816738619152 [label=PreluKernelBackward0]
	139816738619344 -> 139816738619152
	139816738619344 [label=ConvolutionBackward0]
	139816738717856 -> 139816738619344
	139816738717856 [label=AddBackward0]
	139816738618384 -> 139816738717856
	139816738718048 -> 139816738717856
	139816738718048 [label=ConvolutionBackward0]
	139816738615696 -> 139816738718048
	139816738718144 -> 139816738718048
	139820613148704 [label="TCN.TCN.10.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613148704 -> 139816738718144
	139816738718144 [label=AccumulateGrad]
	139816738718096 -> 139816738718048
	139820613148624 [label="TCN.TCN.10.res_out.bias
 (128)" fillcolor=lightblue]
	139820613148624 -> 139816738718096
	139816738718096 [label=AccumulateGrad]
	139816738717808 -> 139816738619344
	139820613190176 [label="TCN.TCN.11.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613190176 -> 139816738717808
	139816738717808 [label=AccumulateGrad]
	139816738717760 -> 139816738619344
	139820613154704 [label="TCN.TCN.11.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613154704 -> 139816738717760
	139816738717760 [label=AccumulateGrad]
	139816738619296 -> 139816738619152
	139816738619296 [label=ViewBackward0]
	139816738718000 -> 139816738619296
	139820613154784 [label="TCN.TCN.11.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613154784 -> 139816738718000
	139816738718000 [label=AccumulateGrad]
	139816738619104 -> 139816738618960
	139820613147984 [label="TCN.TCN.11.reg1.weight
 (512)" fillcolor=lightblue]
	139820613147984 -> 139816738619104
	139816738619104 [label=AccumulateGrad]
	139816738619056 -> 139816738618960
	139820613154544 [label="TCN.TCN.11.reg1.bias
 (512)" fillcolor=lightblue]
	139820613154544 -> 139816738619056
	139816738619056 [label=AccumulateGrad]
	139816738618912 -> 139816738618816
	139820613154624 [label="TCN.TCN.11.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613154624 -> 139816738618912
	139816738618912 [label=AccumulateGrad]
	139816738618864 -> 139816738618816
	139820613148384 [label="TCN.TCN.11.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613148384 -> 139816738618864
	139816738618864 [label=AccumulateGrad]
	139816738618432 -> 139816738618528
	139816738618432 [label=ViewBackward0]
	139816738619248 -> 139816738618432
	139820613148064 [label="TCN.TCN.11.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613148064 -> 139816738619248
	139816738619248 [label=AccumulateGrad]
	139816738618768 -> 139816738616800
	139820613154464 [label="TCN.TCN.11.reg2.weight
 (512)" fillcolor=lightblue]
	139820613154464 -> 139816738618768
	139816738618768 [label=AccumulateGrad]
	139816738618096 -> 139816738616800
	139820613147904 [label="TCN.TCN.11.reg2.bias
 (512)" fillcolor=lightblue]
	139820613147904 -> 139816738618096
	139816738618096 [label=AccumulateGrad]
	139816738616512 -> 139816738604320
	139820613147824 [label="TCN.TCN.11.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613147824 -> 139816738616512
	139816738616512 [label=AccumulateGrad]
	139816738604416 -> 139816738604320
	139820613154384 [label="TCN.TCN.11.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613154384 -> 139816738604416
	139816738604416 [label=AccumulateGrad]
	139816738604176 -> 139816738604080
	139816738604176 [label=ConvolutionBackward0]
	139816738617904 -> 139816738604176
	139816738617904 [label=NativeGroupNormBackward0]
	139816738619008 -> 139816738617904
	139816738619008 [label=PreluKernelBackward0]
	139816738718336 -> 139816738619008
	139816738718336 [label=ConvolutionBackward0]
	139816738718480 -> 139816738718336
	139816738718480 [label=NativeGroupNormBackward0]
	139816738718672 -> 139816738718480
	139816738718672 [label=PreluKernelBackward0]
	139816738718864 -> 139816738718672
	139816738718864 [label=ConvolutionBackward0]
	139816738719008 -> 139816738718864
	139816738719008 [label=AddBackward0]
	139816738717856 -> 139816738719008
	139816738719200 -> 139816738719008
	139816738719200 [label=ConvolutionBackward0]
	139816738616800 -> 139816738719200
	139816738719296 -> 139816738719200
	139820613148304 [label="TCN.TCN.11.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613148304 -> 139816738719296
	139816738719296 [label=AccumulateGrad]
	139816738719248 -> 139816738719200
	139820613154864 [label="TCN.TCN.11.res_out.bias
 (128)" fillcolor=lightblue]
	139820613154864 -> 139816738719248
	139816738719248 [label=AccumulateGrad]
	139816738718960 -> 139816738718864
	139820613154304 [label="TCN.TCN.12.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613154304 -> 139816738718960
	139816738718960 [label=AccumulateGrad]
	139816738718912 -> 139816738718864
	139820613147744 [label="TCN.TCN.12.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613147744 -> 139816738718912
	139816738718912 [label=AccumulateGrad]
	139816738718816 -> 139816738718672
	139816738718816 [label=ViewBackward0]
	139816738719104 -> 139816738718816
	139820613153904 [label="TCN.TCN.12.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613153904 -> 139816738719104
	139816738719104 [label=AccumulateGrad]
	139816738718624 -> 139816738718480
	139820613147344 [label="TCN.TCN.12.reg1.weight
 (512)" fillcolor=lightblue]
	139820613147344 -> 139816738718624
	139816738718624 [label=AccumulateGrad]
	139816738718576 -> 139816738718480
	139820613147264 [label="TCN.TCN.12.reg1.bias
 (512)" fillcolor=lightblue]
	139820613147264 -> 139816738718576
	139816738718576 [label=AccumulateGrad]
	139816738718432 -> 139816738718336
	139820613154224 [label="TCN.TCN.12.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613154224 -> 139816738718432
	139816738718432 [label=AccumulateGrad]
	139816738718384 -> 139816738718336
	139820613154144 [label="TCN.TCN.12.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613154144 -> 139816738718384
	139816738718384 [label=AccumulateGrad]
	139816738717904 -> 139816738619008
	139816738717904 [label=ViewBackward0]
	139816738718768 -> 139816738717904
	139820613153824 [label="TCN.TCN.12.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613153824 -> 139816738718768
	139816738718768 [label=AccumulateGrad]
	139816738619200 -> 139816738617904
	139820613153744 [label="TCN.TCN.12.reg2.weight
 (512)" fillcolor=lightblue]
	139820613153744 -> 139816738619200
	139816738619200 [label=AccumulateGrad]
	139816738718288 -> 139816738617904
	139820613153664 [label="TCN.TCN.12.reg2.bias
 (512)" fillcolor=lightblue]
	139820613153664 -> 139816738718288
	139816738718288 [label=AccumulateGrad]
	139816738617616 -> 139816738604176
	139820613147184 [label="TCN.TCN.12.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613147184 -> 139816738617616
	139816738617616 [label=AccumulateGrad]
	139816738604272 -> 139816738604176
	139820613147104 [label="TCN.TCN.12.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613147104 -> 139816738604272
	139816738604272 [label=AccumulateGrad]
	139816738604032 -> 139816738603936
	139816738604032 [label=ConvolutionBackward0]
	139816738618720 -> 139816738604032
	139816738618720 [label=NativeGroupNormBackward0]
	139816738719152 -> 139816738618720
	139816738719152 [label=PreluKernelBackward0]
	139816738719440 -> 139816738719152
	139816738719440 [label=ConvolutionBackward0]
	139816738719584 -> 139816738719440
	139816738719584 [label=NativeGroupNormBackward0]
	139816738719776 -> 139816738719584
	139816738719776 [label=PreluKernelBackward0]
	139816738719968 -> 139816738719776
	139816738719968 [label=ConvolutionBackward0]
	139816738720112 -> 139816738719968
	139816738720112 [label=AddBackward0]
	139816738719008 -> 139816738720112
	139816738720304 -> 139816738720112
	139816738720304 [label=ConvolutionBackward0]
	139816738617904 -> 139816738720304
	139816738720400 -> 139816738720304
	139820613147504 [label="TCN.TCN.12.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613147504 -> 139816738720400
	139816738720400 [label=AccumulateGrad]
	139816738720352 -> 139816738720304
	139820613147424 [label="TCN.TCN.12.res_out.bias
 (128)" fillcolor=lightblue]
	139820613147424 -> 139816738720352
	139816738720352 [label=AccumulateGrad]
	139816738720064 -> 139816738719968
	139820613153584 [label="TCN.TCN.13.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613153584 -> 139816738720064
	139816738720064 [label=AccumulateGrad]
	139816738720016 -> 139816738719968
	139820613153504 [label="TCN.TCN.13.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613153504 -> 139816738720016
	139816738720016 [label=AccumulateGrad]
	139816738719920 -> 139816738719776
	139816738719920 [label=ViewBackward0]
	139816738720208 -> 139816738719920
	139820613145424 [label="TCN.TCN.13.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139820613145424 -> 139816738720208
	139816738720208 [label=AccumulateGrad]
	139816738719728 -> 139816738719584
	139820613153184 [label="TCN.TCN.13.reg1.weight
 (512)" fillcolor=lightblue]
	139820613153184 -> 139816738719728
	139816738719728 [label=AccumulateGrad]
	139816738719680 -> 139816738719584
	139820613153104 [label="TCN.TCN.13.reg1.bias
 (512)" fillcolor=lightblue]
	139820613153104 -> 139816738719680
	139816738719680 [label=AccumulateGrad]
	139816738719536 -> 139816738719440
	139820613147024 [label="TCN.TCN.13.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613147024 -> 139816738719536
	139816738719536 [label=AccumulateGrad]
	139816738719488 -> 139816738719440
	139820613146944 [label="TCN.TCN.13.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613146944 -> 139816738719488
	139816738719488 [label=AccumulateGrad]
	139816738719056 -> 139816738719152
	139816738719056 [label=ViewBackward0]
	139816738719872 -> 139816738719056
	139820613153264 [label="TCN.TCN.13.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139820613153264 -> 139816738719872
	139816738719872 [label=AccumulateGrad]
	139816738719392 -> 139816738618720
	139820613153024 [label="TCN.TCN.13.reg2.weight
 (512)" fillcolor=lightblue]
	139820613153024 -> 139816738719392
	139816738719392 [label=AccumulateGrad]
	139816738718720 -> 139816738618720
	139820613147664 [label="TCN.TCN.13.reg2.bias
 (512)" fillcolor=lightblue]
	139820613147664 -> 139816738718720
	139816738718720 [label=AccumulateGrad]
	139816738604128 -> 139816738604032
	139820613147584 [label="TCN.TCN.13.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613147584 -> 139816738604128
	139816738604128 [label=AccumulateGrad]
	139816738718240 -> 139816738604032
	139820613154064 [label="TCN.TCN.13.skip_out.bias
 (128)" fillcolor=lightblue]
	139820613154064 -> 139816738718240
	139816738718240 [label=AccumulateGrad]
	139816738603888 -> 139816738603792
	139816738603888 [label=ConvolutionBackward0]
	139816738603984 -> 139816738603888
	139816738603984 [label=NativeGroupNormBackward0]
	139816738720256 -> 139816738603984
	139816738720256 [label=PreluKernelBackward0]
	139816738720544 -> 139816738720256
	139816738720544 [label=ConvolutionBackward0]
	139816738720688 -> 139816738720544
	139816738720688 [label=NativeGroupNormBackward0]
	139816738720880 -> 139816738720688
	139816738720880 [label=PreluKernelBackward0]
	139816738721072 -> 139816738720880
	139816738721072 [label=ConvolutionBackward0]
	139816738721216 -> 139816738721072
	139816738721216 [label=AddBackward0]
	139816738720112 -> 139816738721216
	139816738721408 -> 139816738721216
	139816738721408 [label=ConvolutionBackward0]
	139816738618720 -> 139816738721408
	139816738721504 -> 139816738721408
	139820613153424 [label="TCN.TCN.13.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613153424 -> 139816738721504
	139816738721504 [label=AccumulateGrad]
	139816738721456 -> 139816738721408
	139820613153344 [label="TCN.TCN.13.res_out.bias
 (128)" fillcolor=lightblue]
	139820613153344 -> 139816738721456
	139816738721456 [label=AccumulateGrad]
	139816738721168 -> 139816738721072
	139820613153984 [label="TCN.TCN.14.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139820613153984 -> 139816738721168
	139816738721168 [label=AccumulateGrad]
	139816738721120 -> 139816738721072
	139820613143744 [label="TCN.TCN.14.conv1d.bias
 (512)" fillcolor=lightblue]
	139820613143744 -> 139816738721120
	139816738721120 [label=AccumulateGrad]
	139816738721024 -> 139816738720880
	139816738721024 [label=ViewBackward0]
	139816738721312 -> 139816738721024
	139816742573200 [label="TCN.TCN.14.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816742573200 -> 139816738721312
	139816738721312 [label=AccumulateGrad]
	139816738720832 -> 139816738720688
	139816742574880 [label="TCN.TCN.14.reg1.weight
 (512)" fillcolor=lightblue]
	139816742574880 -> 139816738720832
	139816738720832 [label=AccumulateGrad]
	139816738720784 -> 139816738720688
	139816742574960 [label="TCN.TCN.14.reg1.bias
 (512)" fillcolor=lightblue]
	139816742574960 -> 139816738720784
	139816738720784 [label=AccumulateGrad]
	139816738720640 -> 139816738720544
	139820613152064 [label="TCN.TCN.14.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139820613152064 -> 139816738720640
	139816738720640 [label=AccumulateGrad]
	139816738720592 -> 139816738720544
	139820613151984 [label="TCN.TCN.14.dconv1d.bias
 (512)" fillcolor=lightblue]
	139820613151984 -> 139816738720592
	139816738720592 [label=AccumulateGrad]
	139816738720160 -> 139816738720256
	139816738720160 [label=ViewBackward0]
	139816738720976 -> 139816738720160
	139816742574800 [label="TCN.TCN.14.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816742574800 -> 139816738720976
	139816738720976 [label=AccumulateGrad]
	139816738720496 -> 139816738603984
	139816737937488 [label="TCN.TCN.14.reg2.weight
 (512)" fillcolor=lightblue]
	139816737937488 -> 139816738720496
	139816738720496 [label=AccumulateGrad]
	139816738719824 -> 139816738603984
	139816737937568 [label="TCN.TCN.14.reg2.bias
 (512)" fillcolor=lightblue]
	139816737937568 -> 139816738719824
	139816738719824 [label=AccumulateGrad]
	139816738718528 -> 139816738603888
	139816737937648 [label="TCN.TCN.14.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737937648 -> 139816738718528
	139816738718528 [label=AccumulateGrad]
	139816738717952 -> 139816738603888
	139816737937728 [label="TCN.TCN.14.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737937728 -> 139816738717952
	139816738717952 [label=AccumulateGrad]
	139816738603744 -> 139816738603648
	139816738603744 [label=ConvolutionBackward0]
	139816738603840 -> 139816738603744
	139816738603840 [label=NativeGroupNormBackward0]
	139816738721360 -> 139816738603840
	139816738721360 [label=PreluKernelBackward0]
	139816738721648 -> 139816738721360
	139816738721648 [label=ConvolutionBackward0]
	139816738721792 -> 139816738721648
	139816738721792 [label=NativeGroupNormBackward0]
	139816738721984 -> 139816738721792
	139816738721984 [label=PreluKernelBackward0]
	139816738722176 -> 139816738721984
	139816738722176 [label=ConvolutionBackward0]
	139816738722320 -> 139816738722176
	139816738722320 [label=AddBackward0]
	139816738721216 -> 139816738722320
	139816738722512 -> 139816738722320
	139816738722512 [label=ConvolutionBackward0]
	139816738603984 -> 139816738722512
	139816738722608 -> 139816738722512
	139820613143904 [label="TCN.TCN.14.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139820613143904 -> 139816738722608
	139816738722608 [label=AccumulateGrad]
	139816738722560 -> 139816738722512
	139820613143824 [label="TCN.TCN.14.res_out.bias
 (128)" fillcolor=lightblue]
	139820613143824 -> 139816738722560
	139816738722560 [label=AccumulateGrad]
	139816738722272 -> 139816738722176
	139816737937808 [label="TCN.TCN.15.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737937808 -> 139816738722272
	139816738722272 [label=AccumulateGrad]
	139816738722224 -> 139816738722176
	139816737937888 [label="TCN.TCN.15.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737937888 -> 139816738722224
	139816738722224 [label=AccumulateGrad]
	139816738722128 -> 139816738721984
	139816738722128 [label=ViewBackward0]
	139816738722416 -> 139816738722128
	139816737938288 [label="TCN.TCN.15.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737938288 -> 139816738722416
	139816738722416 [label=AccumulateGrad]
	139816738721936 -> 139816738721792
	139816737938448 [label="TCN.TCN.15.reg1.weight
 (512)" fillcolor=lightblue]
	139816737938448 -> 139816738721936
	139816738721936 [label=AccumulateGrad]
	139816738721888 -> 139816738721792
	139816737938528 [label="TCN.TCN.15.reg1.bias
 (512)" fillcolor=lightblue]
	139816737938528 -> 139816738721888
	139816738721888 [label=AccumulateGrad]
	139816738721744 -> 139816738721648
	139816737937968 [label="TCN.TCN.15.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737937968 -> 139816738721744
	139816738721744 [label=AccumulateGrad]
	139816738721696 -> 139816738721648
	139816737938048 [label="TCN.TCN.15.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737938048 -> 139816738721696
	139816738721696 [label=AccumulateGrad]
	139816738721264 -> 139816738721360
	139816738721264 [label=ViewBackward0]
	139816738722080 -> 139816738721264
	139816737938368 [label="TCN.TCN.15.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737938368 -> 139816738722080
	139816738722080 [label=AccumulateGrad]
	139816738721600 -> 139816738603840
	139816737938608 [label="TCN.TCN.15.reg2.weight
 (512)" fillcolor=lightblue]
	139816737938608 -> 139816738721600
	139816738721600 [label=AccumulateGrad]
	139816738720928 -> 139816738603840
	139816737938688 [label="TCN.TCN.15.reg2.bias
 (512)" fillcolor=lightblue]
	139816737938688 -> 139816738720928
	139816738720928 [label=AccumulateGrad]
	139816738719632 -> 139816738603744
	139816737938768 [label="TCN.TCN.15.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737938768 -> 139816738719632
	139816738719632 [label=AccumulateGrad]
	139816738719344 -> 139816738603744
	139816737938848 [label="TCN.TCN.15.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737938848 -> 139816738719344
	139816738719344 [label=AccumulateGrad]
	139816738603600 -> 139816738603504
	139816738603600 [label=ConvolutionBackward0]
	139816738603696 -> 139816738603600
	139816738603696 [label=NativeGroupNormBackward0]
	139816738722464 -> 139816738603696
	139816738722464 [label=PreluKernelBackward0]
	139816738722752 -> 139816738722464
	139816738722752 [label=ConvolutionBackward0]
	139816738722896 -> 139816738722752
	139816738722896 [label=NativeGroupNormBackward0]
	139816738723088 -> 139816738722896
	139816738723088 [label=PreluKernelBackward0]
	139816738723280 -> 139816738723088
	139816738723280 [label=ConvolutionBackward0]
	139816738723424 -> 139816738723280
	139816738723424 [label=AddBackward0]
	139816738722320 -> 139816738723424
	139816738723616 -> 139816738723424
	139816738723616 [label=ConvolutionBackward0]
	139816738603840 -> 139816738723616
	139816738723712 -> 139816738723616
	139816737938128 [label="TCN.TCN.15.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737938128 -> 139816738723712
	139816738723712 [label=AccumulateGrad]
	139816738723664 -> 139816738723616
	139816737938208 [label="TCN.TCN.15.res_out.bias
 (128)" fillcolor=lightblue]
	139816737938208 -> 139816738723664
	139816738723664 [label=AccumulateGrad]
	139816738723376 -> 139816738723280
	139816737938928 [label="TCN.TCN.16.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737938928 -> 139816738723376
	139816738723376 [label=AccumulateGrad]
	139816738723328 -> 139816738723280
	139816737939008 [label="TCN.TCN.16.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737939008 -> 139816738723328
	139816738723328 [label=AccumulateGrad]
	139816738723232 -> 139816738723088
	139816738723232 [label=ViewBackward0]
	139816738723520 -> 139816738723232
	139816737939408 [label="TCN.TCN.16.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737939408 -> 139816738723520
	139816738723520 [label=AccumulateGrad]
	139816738723040 -> 139816738722896
	139816737939568 [label="TCN.TCN.16.reg1.weight
 (512)" fillcolor=lightblue]
	139816737939568 -> 139816738723040
	139816738723040 [label=AccumulateGrad]
	139816738722992 -> 139816738722896
	139816737939648 [label="TCN.TCN.16.reg1.bias
 (512)" fillcolor=lightblue]
	139816737939648 -> 139816738722992
	139816738722992 [label=AccumulateGrad]
	139816738722848 -> 139816738722752
	139816737939088 [label="TCN.TCN.16.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737939088 -> 139816738722848
	139816738722848 [label=AccumulateGrad]
	139816738722800 -> 139816738722752
	139816737939168 [label="TCN.TCN.16.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737939168 -> 139816738722800
	139816738722800 [label=AccumulateGrad]
	139816738722368 -> 139816738722464
	139816738722368 [label=ViewBackward0]
	139816738723184 -> 139816738722368
	139816737939488 [label="TCN.TCN.16.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737939488 -> 139816738723184
	139816738723184 [label=AccumulateGrad]
	139816738722704 -> 139816738603696
	139816737939728 [label="TCN.TCN.16.reg2.weight
 (512)" fillcolor=lightblue]
	139816737939728 -> 139816738722704
	139816738722704 [label=AccumulateGrad]
	139816738722032 -> 139816738603696
	139816737939808 [label="TCN.TCN.16.reg2.bias
 (512)" fillcolor=lightblue]
	139816737939808 -> 139816738722032
	139816738722032 [label=AccumulateGrad]
	139816738720736 -> 139816738603600
	139816737939888 [label="TCN.TCN.16.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737939888 -> 139816738720736
	139816738720736 [label=AccumulateGrad]
	139816738720448 -> 139816738603600
	139816737939968 [label="TCN.TCN.16.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737939968 -> 139816738720448
	139816738720448 [label=AccumulateGrad]
	139816738603456 -> 139816738603360
	139816738603456 [label=ConvolutionBackward0]
	139816738603552 -> 139816738603456
	139816738603552 [label=NativeGroupNormBackward0]
	139816738723568 -> 139816738603552
	139816738723568 [label=PreluKernelBackward0]
	139816738723856 -> 139816738723568
	139816738723856 [label=ConvolutionBackward0]
	139816738724000 -> 139816738723856
	139816738724000 [label=NativeGroupNormBackward0]
	139816738724192 -> 139816738724000
	139816738724192 [label=PreluKernelBackward0]
	139816738724384 -> 139816738724192
	139816738724384 [label=ConvolutionBackward0]
	139816738724528 -> 139816738724384
	139816738724528 [label=AddBackward0]
	139816738723424 -> 139816738724528
	139816738724720 -> 139816738724528
	139816738724720 [label=ConvolutionBackward0]
	139816738603696 -> 139816738724720
	139816738724816 -> 139816738724720
	139816737939248 [label="TCN.TCN.16.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737939248 -> 139816738724816
	139816738724816 [label=AccumulateGrad]
	139816738724768 -> 139816738724720
	139816737939328 [label="TCN.TCN.16.res_out.bias
 (128)" fillcolor=lightblue]
	139816737939328 -> 139816738724768
	139816738724768 [label=AccumulateGrad]
	139816738724480 -> 139816738724384
	139816737940048 [label="TCN.TCN.17.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737940048 -> 139816738724480
	139816738724480 [label=AccumulateGrad]
	139816738724432 -> 139816738724384
	139816737940128 [label="TCN.TCN.17.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737940128 -> 139816738724432
	139816738724432 [label=AccumulateGrad]
	139816738724336 -> 139816738724192
	139816738724336 [label=ViewBackward0]
	139816738724624 -> 139816738724336
	139816737940528 [label="TCN.TCN.17.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737940528 -> 139816738724624
	139816738724624 [label=AccumulateGrad]
	139816738724144 -> 139816738724000
	139816737940688 [label="TCN.TCN.17.reg1.weight
 (512)" fillcolor=lightblue]
	139816737940688 -> 139816738724144
	139816738724144 [label=AccumulateGrad]
	139816738724096 -> 139816738724000
	139816737940768 [label="TCN.TCN.17.reg1.bias
 (512)" fillcolor=lightblue]
	139816737940768 -> 139816738724096
	139816738724096 [label=AccumulateGrad]
	139816738723952 -> 139816738723856
	139816737940208 [label="TCN.TCN.17.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737940208 -> 139816738723952
	139816738723952 [label=AccumulateGrad]
	139816738723904 -> 139816738723856
	139816737940288 [label="TCN.TCN.17.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737940288 -> 139816738723904
	139816738723904 [label=AccumulateGrad]
	139816738723472 -> 139816738723568
	139816738723472 [label=ViewBackward0]
	139816738724288 -> 139816738723472
	139816737940608 [label="TCN.TCN.17.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737940608 -> 139816738724288
	139816738724288 [label=AccumulateGrad]
	139816738723808 -> 139816738603552
	139816737940848 [label="TCN.TCN.17.reg2.weight
 (512)" fillcolor=lightblue]
	139816737940848 -> 139816738723808
	139816738723808 [label=AccumulateGrad]
	139816738723136 -> 139816738603552
	139816737940928 [label="TCN.TCN.17.reg2.bias
 (512)" fillcolor=lightblue]
	139816737940928 -> 139816738723136
	139816738723136 [label=AccumulateGrad]
	139816738721840 -> 139816738603456
	139816737941008 [label="TCN.TCN.17.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737941008 -> 139816738721840
	139816738721840 [label=AccumulateGrad]
	139816738721552 -> 139816738603456
	139816737941088 [label="TCN.TCN.17.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737941088 -> 139816738721552
	139816738721552 [label=AccumulateGrad]
	139816738603312 -> 139816738603216
	139816738603312 [label=ConvolutionBackward0]
	139816738603408 -> 139816738603312
	139816738603408 [label=NativeGroupNormBackward0]
	139816738724672 -> 139816738603408
	139816738724672 [label=PreluKernelBackward0]
	139816738724960 -> 139816738724672
	139816738724960 [label=ConvolutionBackward0]
	139816738725104 -> 139816738724960
	139816738725104 [label=NativeGroupNormBackward0]
	139816738725296 -> 139816738725104
	139816738725296 [label=PreluKernelBackward0]
	139816738725488 -> 139816738725296
	139816738725488 [label=ConvolutionBackward0]
	139816738725632 -> 139816738725488
	139816738725632 [label=AddBackward0]
	139816738724528 -> 139816738725632
	139816738725824 -> 139816738725632
	139816738725824 [label=ConvolutionBackward0]
	139816738603552 -> 139816738725824
	139816738725920 -> 139816738725824
	139816737940368 [label="TCN.TCN.17.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737940368 -> 139816738725920
	139816738725920 [label=AccumulateGrad]
	139816738725872 -> 139816738725824
	139816737940448 [label="TCN.TCN.17.res_out.bias
 (128)" fillcolor=lightblue]
	139816737940448 -> 139816738725872
	139816738725872 [label=AccumulateGrad]
	139816738725584 -> 139816738725488
	139816737941168 [label="TCN.TCN.18.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737941168 -> 139816738725584
	139816738725584 [label=AccumulateGrad]
	139816738725536 -> 139816738725488
	139816737941248 [label="TCN.TCN.18.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737941248 -> 139816738725536
	139816738725536 [label=AccumulateGrad]
	139816738725440 -> 139816738725296
	139816738725440 [label=ViewBackward0]
	139816738725728 -> 139816738725440
	139816737941648 [label="TCN.TCN.18.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737941648 -> 139816738725728
	139816738725728 [label=AccumulateGrad]
	139816738725248 -> 139816738725104
	139816737941808 [label="TCN.TCN.18.reg1.weight
 (512)" fillcolor=lightblue]
	139816737941808 -> 139816738725248
	139816738725248 [label=AccumulateGrad]
	139816738725200 -> 139816738725104
	139816737941888 [label="TCN.TCN.18.reg1.bias
 (512)" fillcolor=lightblue]
	139816737941888 -> 139816738725200
	139816738725200 [label=AccumulateGrad]
	139816738725056 -> 139816738724960
	139816737941328 [label="TCN.TCN.18.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737941328 -> 139816738725056
	139816738725056 [label=AccumulateGrad]
	139816738725008 -> 139816738724960
	139816737941408 [label="TCN.TCN.18.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737941408 -> 139816738725008
	139816738725008 [label=AccumulateGrad]
	139816738724576 -> 139816738724672
	139816738724576 [label=ViewBackward0]
	139816738725392 -> 139816738724576
	139816737941728 [label="TCN.TCN.18.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737941728 -> 139816738725392
	139816738725392 [label=AccumulateGrad]
	139816738724912 -> 139816738603408
	139816737941968 [label="TCN.TCN.18.reg2.weight
 (512)" fillcolor=lightblue]
	139816737941968 -> 139816738724912
	139816738724912 [label=AccumulateGrad]
	139816738724240 -> 139816738603408
	139816737942048 [label="TCN.TCN.18.reg2.bias
 (512)" fillcolor=lightblue]
	139816737942048 -> 139816738724240
	139816738724240 [label=AccumulateGrad]
	139816738722944 -> 139816738603312
	139816737942128 [label="TCN.TCN.18.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737942128 -> 139816738722944
	139816738722944 [label=AccumulateGrad]
	139816738722656 -> 139816738603312
	139816737942208 [label="TCN.TCN.18.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737942208 -> 139816738722656
	139816738722656 [label=AccumulateGrad]
	139816738603168 -> 139816738389968
	139816738603168 [label=ConvolutionBackward0]
	139816738603264 -> 139816738603168
	139816738603264 [label=NativeGroupNormBackward0]
	139816738725776 -> 139816738603264
	139816738725776 [label=PreluKernelBackward0]
	139816738726064 -> 139816738725776
	139816738726064 [label=ConvolutionBackward0]
	139816738726208 -> 139816738726064
	139816738726208 [label=NativeGroupNormBackward0]
	139816738726400 -> 139816738726208
	139816738726400 [label=PreluKernelBackward0]
	139816738726592 -> 139816738726400
	139816738726592 [label=ConvolutionBackward0]
	139816738726736 -> 139816738726592
	139816738726736 [label=AddBackward0]
	139816738725632 -> 139816738726736
	139816738726928 -> 139816738726736
	139816738726928 [label=ConvolutionBackward0]
	139816738603408 -> 139816738726928
	139816738727024 -> 139816738726928
	139816737941488 [label="TCN.TCN.18.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737941488 -> 139816738727024
	139816738727024 [label=AccumulateGrad]
	139816738726976 -> 139816738726928
	139816737941568 [label="TCN.TCN.18.res_out.bias
 (128)" fillcolor=lightblue]
	139816737941568 -> 139816738726976
	139816738726976 [label=AccumulateGrad]
	139816738726688 -> 139816738726592
	139816737942288 [label="TCN.TCN.19.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737942288 -> 139816738726688
	139816738726688 [label=AccumulateGrad]
	139816738726640 -> 139816738726592
	139816737942368 [label="TCN.TCN.19.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737942368 -> 139816738726640
	139816738726640 [label=AccumulateGrad]
	139816738726544 -> 139816738726400
	139816738726544 [label=ViewBackward0]
	139816738726832 -> 139816738726544
	139816737942768 [label="TCN.TCN.19.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737942768 -> 139816738726832
	139816738726832 [label=AccumulateGrad]
	139816738726352 -> 139816738726208
	139816737942928 [label="TCN.TCN.19.reg1.weight
 (512)" fillcolor=lightblue]
	139816737942928 -> 139816738726352
	139816738726352 [label=AccumulateGrad]
	139816738726304 -> 139816738726208
	139816737943008 [label="TCN.TCN.19.reg1.bias
 (512)" fillcolor=lightblue]
	139816737943008 -> 139816738726304
	139816738726304 [label=AccumulateGrad]
	139816738726160 -> 139816738726064
	139816737942448 [label="TCN.TCN.19.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737942448 -> 139816738726160
	139816738726160 [label=AccumulateGrad]
	139816738726112 -> 139816738726064
	139816737942528 [label="TCN.TCN.19.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737942528 -> 139816738726112
	139816738726112 [label=AccumulateGrad]
	139816738725680 -> 139816738725776
	139816738725680 [label=ViewBackward0]
	139816738726496 -> 139816738725680
	139816737942848 [label="TCN.TCN.19.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737942848 -> 139816738726496
	139816738726496 [label=AccumulateGrad]
	139816738726016 -> 139816738603264
	139816737943088 [label="TCN.TCN.19.reg2.weight
 (512)" fillcolor=lightblue]
	139816737943088 -> 139816738726016
	139816738726016 [label=AccumulateGrad]
	139816738725344 -> 139816738603264
	139816737943168 [label="TCN.TCN.19.reg2.bias
 (512)" fillcolor=lightblue]
	139816737943168 -> 139816738725344
	139816738725344 [label=AccumulateGrad]
	139816738724048 -> 139816738603168
	139816737943248 [label="TCN.TCN.19.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737943248 -> 139816738724048
	139816738724048 [label=AccumulateGrad]
	139816738723760 -> 139816738603168
	139816737943328 [label="TCN.TCN.19.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737943328 -> 139816738723760
	139816738723760 [label=AccumulateGrad]
	139816738389920 -> 139816738389872
	139816738389920 [label=ConvolutionBackward0]
	139816738603120 -> 139816738389920
	139816738603120 [label=NativeGroupNormBackward0]
	139816738726880 -> 139816738603120
	139816738726880 [label=PreluKernelBackward0]
	139816738727168 -> 139816738726880
	139816738727168 [label=ConvolutionBackward0]
	139816738727312 -> 139816738727168
	139816738727312 [label=NativeGroupNormBackward0]
	139816738727504 -> 139816738727312
	139816738727504 [label=PreluKernelBackward0]
	139816738727696 -> 139816738727504
	139816738727696 [label=ConvolutionBackward0]
	139816738727840 -> 139816738727696
	139816738727840 [label=AddBackward0]
	139816738726736 -> 139816738727840
	139816738728032 -> 139816738727840
	139816738728032 [label=ConvolutionBackward0]
	139816738603264 -> 139816738728032
	139816738728128 -> 139816738728032
	139816737942608 [label="TCN.TCN.19.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737942608 -> 139816738728128
	139816738728128 [label=AccumulateGrad]
	139816738728080 -> 139816738728032
	139816737942688 [label="TCN.TCN.19.res_out.bias
 (128)" fillcolor=lightblue]
	139816737942688 -> 139816738728080
	139816738728080 [label=AccumulateGrad]
	139816738727792 -> 139816738727696
	139816737943408 [label="TCN.TCN.20.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737943408 -> 139816738727792
	139816738727792 [label=AccumulateGrad]
	139816738727744 -> 139816738727696
	139816737943488 [label="TCN.TCN.20.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737943488 -> 139816738727744
	139816738727744 [label=AccumulateGrad]
	139816738727648 -> 139816738727504
	139816738727648 [label=ViewBackward0]
	139816738727936 -> 139816738727648
	139816737943888 [label="TCN.TCN.20.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737943888 -> 139816738727936
	139816738727936 [label=AccumulateGrad]
	139816738727456 -> 139816738727312
	139816737944048 [label="TCN.TCN.20.reg1.weight
 (512)" fillcolor=lightblue]
	139816737944048 -> 139816738727456
	139816738727456 [label=AccumulateGrad]
	139816738727408 -> 139816738727312
	139816737944128 [label="TCN.TCN.20.reg1.bias
 (512)" fillcolor=lightblue]
	139816737944128 -> 139816738727408
	139816738727408 [label=AccumulateGrad]
	139816738727264 -> 139816738727168
	139816737943568 [label="TCN.TCN.20.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737943568 -> 139816738727264
	139816738727264 [label=AccumulateGrad]
	139816738727216 -> 139816738727168
	139816737943648 [label="TCN.TCN.20.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737943648 -> 139816738727216
	139816738727216 [label=AccumulateGrad]
	139816738726784 -> 139816738726880
	139816738726784 [label=ViewBackward0]
	139816738727600 -> 139816738726784
	139816737943968 [label="TCN.TCN.20.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737943968 -> 139816738727600
	139816738727600 [label=AccumulateGrad]
	139816738727120 -> 139816738603120
	139816737944208 [label="TCN.TCN.20.reg2.weight
 (512)" fillcolor=lightblue]
	139816737944208 -> 139816738727120
	139816738727120 [label=AccumulateGrad]
	139816738726448 -> 139816738603120
	139816737944288 [label="TCN.TCN.20.reg2.bias
 (512)" fillcolor=lightblue]
	139816737944288 -> 139816738726448
	139816738726448 [label=AccumulateGrad]
	139816738725152 -> 139816738389920
	139816737944368 [label="TCN.TCN.20.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737944368 -> 139816738725152
	139816738725152 [label=AccumulateGrad]
	139816738724864 -> 139816738389920
	139816737944448 [label="TCN.TCN.20.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737944448 -> 139816738724864
	139816738724864 [label=AccumulateGrad]
	139816738389824 -> 139816738389728
	139816738389824 [label=ConvolutionBackward0]
	139816738603072 -> 139816738389824
	139816738603072 [label=NativeGroupNormBackward0]
	139816738727984 -> 139816738603072
	139816738727984 [label=PreluKernelBackward0]
	139816738728272 -> 139816738727984
	139816738728272 [label=ConvolutionBackward0]
	139816738728416 -> 139816738728272
	139816738728416 [label=NativeGroupNormBackward0]
	139816738728608 -> 139816738728416
	139816738728608 [label=PreluKernelBackward0]
	139816738728800 -> 139816738728608
	139816738728800 [label=ConvolutionBackward0]
	139816738728944 -> 139816738728800
	139816738728944 [label=AddBackward0]
	139816738727840 -> 139816738728944
	139816738729136 -> 139816738728944
	139816738729136 [label=ConvolutionBackward0]
	139816738603120 -> 139816738729136
	139816738729232 -> 139816738729136
	139816737943728 [label="TCN.TCN.20.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737943728 -> 139816738729232
	139816738729232 [label=AccumulateGrad]
	139816738729184 -> 139816738729136
	139816737943808 [label="TCN.TCN.20.res_out.bias
 (128)" fillcolor=lightblue]
	139816737943808 -> 139816738729184
	139816738729184 [label=AccumulateGrad]
	139816738728896 -> 139816738728800
	139816737944528 [label="TCN.TCN.21.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737944528 -> 139816738728896
	139816738728896 [label=AccumulateGrad]
	139816738728848 -> 139816738728800
	139816737944608 [label="TCN.TCN.21.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737944608 -> 139816738728848
	139816738728848 [label=AccumulateGrad]
	139816738728752 -> 139816738728608
	139816738728752 [label=ViewBackward0]
	139816738729040 -> 139816738728752
	139816737945008 [label="TCN.TCN.21.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737945008 -> 139816738729040
	139816738729040 [label=AccumulateGrad]
	139816738728560 -> 139816738728416
	139816737945168 [label="TCN.TCN.21.reg1.weight
 (512)" fillcolor=lightblue]
	139816737945168 -> 139816738728560
	139816738728560 [label=AccumulateGrad]
	139816738728512 -> 139816738728416
	139816737945248 [label="TCN.TCN.21.reg1.bias
 (512)" fillcolor=lightblue]
	139816737945248 -> 139816738728512
	139816738728512 [label=AccumulateGrad]
	139816738728368 -> 139816738728272
	139816737944688 [label="TCN.TCN.21.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737944688 -> 139816738728368
	139816738728368 [label=AccumulateGrad]
	139816738728320 -> 139816738728272
	139816737944768 [label="TCN.TCN.21.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737944768 -> 139816738728320
	139816738728320 [label=AccumulateGrad]
	139816738727888 -> 139816738727984
	139816738727888 [label=ViewBackward0]
	139816738728704 -> 139816738727888
	139816737945088 [label="TCN.TCN.21.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737945088 -> 139816738728704
	139816738728704 [label=AccumulateGrad]
	139816738728224 -> 139816738603072
	139816737945328 [label="TCN.TCN.21.reg2.weight
 (512)" fillcolor=lightblue]
	139816737945328 -> 139816738728224
	139816738728224 [label=AccumulateGrad]
	139816738727552 -> 139816738603072
	139816737945408 [label="TCN.TCN.21.reg2.bias
 (512)" fillcolor=lightblue]
	139816737945408 -> 139816738727552
	139816738727552 [label=AccumulateGrad]
	139816738726256 -> 139816738389824
	139816737945488 [label="TCN.TCN.21.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737945488 -> 139816738726256
	139816738726256 [label=AccumulateGrad]
	139816738725968 -> 139816738389824
	139816737945568 [label="TCN.TCN.21.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737945568 -> 139816738725968
	139816738725968 [label=AccumulateGrad]
	139816738389680 -> 139816738389584
	139816738389680 [label=ConvolutionBackward0]
	139816738389776 -> 139816738389680
	139816738389776 [label=NativeGroupNormBackward0]
	139816738729088 -> 139816738389776
	139816738729088 [label=PreluKernelBackward0]
	139816738729376 -> 139816738729088
	139816738729376 [label=ConvolutionBackward0]
	139816738729520 -> 139816738729376
	139816738729520 [label=NativeGroupNormBackward0]
	139816738729712 -> 139816738729520
	139816738729712 [label=PreluKernelBackward0]
	139816738729904 -> 139816738729712
	139816738729904 [label=ConvolutionBackward0]
	139816738730048 -> 139816738729904
	139816738730048 [label=AddBackward0]
	139816738728944 -> 139816738730048
	139816738730240 -> 139816738730048
	139816738730240 [label=ConvolutionBackward0]
	139816738603072 -> 139816738730240
	139816738730336 -> 139816738730240
	139816737944848 [label="TCN.TCN.21.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737944848 -> 139816738730336
	139816738730336 [label=AccumulateGrad]
	139816738730288 -> 139816738730240
	139816737944928 [label="TCN.TCN.21.res_out.bias
 (128)" fillcolor=lightblue]
	139816737944928 -> 139816738730288
	139816738730288 [label=AccumulateGrad]
	139816738730000 -> 139816738729904
	139816737945648 [label="TCN.TCN.22.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737945648 -> 139816738730000
	139816738730000 [label=AccumulateGrad]
	139816738729952 -> 139816738729904
	139816737945728 [label="TCN.TCN.22.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737945728 -> 139816738729952
	139816738729952 [label=AccumulateGrad]
	139816738729856 -> 139816738729712
	139816738729856 [label=ViewBackward0]
	139816738730144 -> 139816738729856
	139816737946128 [label="TCN.TCN.22.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737946128 -> 139816738730144
	139816738730144 [label=AccumulateGrad]
	139816738729664 -> 139816738729520
	139816737946288 [label="TCN.TCN.22.reg1.weight
 (512)" fillcolor=lightblue]
	139816737946288 -> 139816738729664
	139816738729664 [label=AccumulateGrad]
	139816738729616 -> 139816738729520
	139816737946368 [label="TCN.TCN.22.reg1.bias
 (512)" fillcolor=lightblue]
	139816737946368 -> 139816738729616
	139816738729616 [label=AccumulateGrad]
	139816738729472 -> 139816738729376
	139816737945808 [label="TCN.TCN.22.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737945808 -> 139816738729472
	139816738729472 [label=AccumulateGrad]
	139816738729424 -> 139816738729376
	139816737945888 [label="TCN.TCN.22.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737945888 -> 139816738729424
	139816738729424 [label=AccumulateGrad]
	139816738728992 -> 139816738729088
	139816738728992 [label=ViewBackward0]
	139816738729808 -> 139816738728992
	139816737946208 [label="TCN.TCN.22.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737946208 -> 139816738729808
	139816738729808 [label=AccumulateGrad]
	139816738729328 -> 139816738389776
	139816737946448 [label="TCN.TCN.22.reg2.weight
 (512)" fillcolor=lightblue]
	139816737946448 -> 139816738729328
	139816738729328 [label=AccumulateGrad]
	139816738728656 -> 139816738389776
	139816737946528 [label="TCN.TCN.22.reg2.bias
 (512)" fillcolor=lightblue]
	139816737946528 -> 139816738728656
	139816738728656 [label=AccumulateGrad]
	139816738727360 -> 139816738389680
	139816737946608 [label="TCN.TCN.22.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737946608 -> 139816738727360
	139816738727360 [label=AccumulateGrad]
	139816738727072 -> 139816738389680
	139816737946688 [label="TCN.TCN.22.skip_out.bias
 (128)" fillcolor=lightblue]
	139816737946688 -> 139816738727072
	139816738727072 [label=AccumulateGrad]
	139816738389536 -> 139816738389440
	139816738389536 [label=ConvolutionBackward0]
	139816738389632 -> 139816738389536
	139816738389632 [label=NativeGroupNormBackward0]
	139816738730192 -> 139816738389632
	139816738730192 [label=PreluKernelBackward0]
	139816738730480 -> 139816738730192
	139816738730480 [label=ConvolutionBackward0]
	139816738730624 -> 139816738730480
	139816738730624 [label=NativeGroupNormBackward0]
	139816738730816 -> 139816738730624
	139816738730816 [label=PreluKernelBackward0]
	139816738731008 -> 139816738730816
	139816738731008 [label=ConvolutionBackward0]
	139816738731152 -> 139816738731008
	139816738731152 [label=AddBackward0]
	139816738730048 -> 139816738731152
	139816738731344 -> 139816738731152
	139816738731344 [label=ConvolutionBackward0]
	139816738389776 -> 139816738731344
	139816738731440 -> 139816738731344
	139816737945968 [label="TCN.TCN.22.res_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816737945968 -> 139816738731440
	139816738731440 [label=AccumulateGrad]
	139816738731392 -> 139816738731344
	139816737946048 [label="TCN.TCN.22.res_out.bias
 (128)" fillcolor=lightblue]
	139816737946048 -> 139816738731392
	139816738731392 [label=AccumulateGrad]
	139816738731104 -> 139816738731008
	139816737946768 [label="TCN.TCN.23.conv1d.weight
 (512, 128, 1)" fillcolor=lightblue]
	139816737946768 -> 139816738731104
	139816738731104 [label=AccumulateGrad]
	139816738731056 -> 139816738731008
	139816737946848 [label="TCN.TCN.23.conv1d.bias
 (512)" fillcolor=lightblue]
	139816737946848 -> 139816738731056
	139816738731056 [label=AccumulateGrad]
	139816738730960 -> 139816738730816
	139816738730960 [label=ViewBackward0]
	139816738731248 -> 139816738730960
	139816737947248 [label="TCN.TCN.23.nonlinearity1.weight
 (1)" fillcolor=lightblue]
	139816737947248 -> 139816738731248
	139816738731248 [label=AccumulateGrad]
	139816738730768 -> 139816738730624
	139816737947408 [label="TCN.TCN.23.reg1.weight
 (512)" fillcolor=lightblue]
	139816737947408 -> 139816738730768
	139816738730768 [label=AccumulateGrad]
	139816738730720 -> 139816738730624
	139816737947488 [label="TCN.TCN.23.reg1.bias
 (512)" fillcolor=lightblue]
	139816737947488 -> 139816738730720
	139816738730720 [label=AccumulateGrad]
	139816738730576 -> 139816738730480
	139816737946928 [label="TCN.TCN.23.dconv1d.weight
 (512, 1, 3)" fillcolor=lightblue]
	139816737946928 -> 139816738730576
	139816738730576 [label=AccumulateGrad]
	139816738730528 -> 139816738730480
	139816737947008 [label="TCN.TCN.23.dconv1d.bias
 (512)" fillcolor=lightblue]
	139816737947008 -> 139816738730528
	139816738730528 [label=AccumulateGrad]
	139816738730096 -> 139816738730192
	139816738730096 [label=ViewBackward0]
	139816738730912 -> 139816738730096
	139816737947328 [label="TCN.TCN.23.nonlinearity2.weight
 (1)" fillcolor=lightblue]
	139816737947328 -> 139816738730912
	139816738730912 [label=AccumulateGrad]
	139816738730432 -> 139816738389632
	139816737947568 [label="TCN.TCN.23.reg2.weight
 (512)" fillcolor=lightblue]
	139816737947568 -> 139816738730432
	139816738730432 [label=AccumulateGrad]
	139816738729760 -> 139816738389632
	139816738521152 [label="TCN.TCN.23.reg2.bias
 (512)" fillcolor=lightblue]
	139816738521152 -> 139816738729760
	139816738729760 [label=AccumulateGrad]
	139816738728464 -> 139816738389536
	139816738521232 [label="TCN.TCN.23.skip_out.weight
 (128, 512, 1)" fillcolor=lightblue]
	139816738521232 -> 139816738728464
	139816738728464 [label=AccumulateGrad]
	139816738728176 -> 139816738389536
	139816738521312 [label="TCN.TCN.23.skip_out.bias
 (128)" fillcolor=lightblue]
	139816738521312 -> 139816738728176
	139816738728176 [label=AccumulateGrad]
	139816738389392 -> 139816738389248
	139816738389392 [label=ViewBackward0]
	139816738389488 -> 139816738389392
	139816743877696 [label="TCN.output.0.weight
 (1)" fillcolor=lightblue]
	139816743877696 -> 139816738389488
	139816738389488 [label=AccumulateGrad]
	139816738389200 -> 139816738387088
	139816738521392 [label="TCN.output.1.weight
 (1024, 128, 1)" fillcolor=lightblue]
	139816738521392 -> 139816738389200
	139816738389200 [label=AccumulateGrad]
	139816738386848 -> 139816738387088
	139816738521472 [label="TCN.output.1.bias
 (1024)" fillcolor=lightblue]
	139816738521472 -> 139816738386848
	139816738386848 [label=AccumulateGrad]
	139816738388048 -> 139816738388240
	139816742826080 [label="decoder.weight
 (512, 1, 32)" fillcolor=lightblue]
	139816742826080 -> 139816738388048
	139816738388048 [label=AccumulateGrad]
	139816738389056 -> 139816738535472
	139816738535632 [label="
 (4, 1, 32000)" fillcolor=darkolivegreen3]
	139816738388480 -> 139816738535632
	139816738535632 -> 139816738535472 [style=dotted]
}
